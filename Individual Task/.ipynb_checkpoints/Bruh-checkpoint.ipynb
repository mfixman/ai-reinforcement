{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"ray[rllib]\" torch\n",
    "# this is needed\n",
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7ed3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray, version 2.20.0\n",
      "Python 3.11.5\n"
     ]
    }
   ],
   "source": [
    "!ray --version\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf2583a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import ray\n",
    "import ray.rllib.algorithms.dqn as dqn\n",
    "from ray.tune.logger import pretty_print\n",
    "from ray import tune\n",
    "\n",
    "import pickle\n",
    "import GPUtil\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from ray.rllib.algorithms.dqn.dqn import DQNConfig\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca40f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['extra_python_environs_for_driver', 'extra_python_environs_for_worker', 'num_gpus', 'num_cpus_per_worker', 'num_gpus_per_worker', '_fake_gpus', 'num_learner_workers', 'num_gpus_per_learner_worker', 'num_cpus_per_learner_worker', 'local_gpu_idx', 'custom_resources_per_worker', 'placement_strategy', 'eager_tracing', 'eager_max_retraces', 'tf_session_args', 'local_tf_session_args', 'torch_compile_learner', 'torch_compile_learner_what_to_compile', 'torch_compile_learner_dynamo_backend', 'torch_compile_learner_dynamo_mode', 'torch_compile_worker', 'torch_compile_worker_dynamo_backend', 'torch_compile_worker_dynamo_mode', 'env', 'env_config', 'observation_space', 'action_space', 'clip_rewards', 'normalize_actions', 'clip_actions', '_is_atari', 'env_task_fn', 'render_env', 'action_mask_key', 'env_runner_cls', 'num_envs_per_env_runner', 'validate_env_runners_after_construction', 'sample_timeout_s', '_env_to_module_connector', 'add_default_connectors_to_env_to_module_pipeline', '_module_to_env_connector', 'add_default_connectors_to_module_to_env_pipeline', 'episode_lookback_horizon', 'rollout_fragment_length', 'batch_mode', 'compress_observations', 'remote_worker_envs', 'remote_env_batch_wait_ms', 'enable_tf1_exec_eagerly', 'sample_collector', 'preprocessor_pref', 'observation_filter', 'update_worker_filter_stats', 'use_worker_filter_stats', 'enable_connectors', 'sampler_perf_stats_ema_coef', 'gamma', 'lr', 'grad_clip', 'grad_clip_by', 'train_batch_size', 'train_batch_size_per_learner', 'model', '_learner_connector', 'add_default_connectors_to_learner_pipeline', 'optimizer', 'max_requests_in_flight_per_sampler_worker', '_learner_class', 'explore', 'exploration_config', 'algorithm_config_overrides_per_module', '_per_module_overrides', 'count_steps_by', 'policy_map_capacity', 'policy_mapping_fn', 'policies_to_train', 'policy_states_are_swappable', 'observation_fn', 'input_config', 'actions_in_input_normalized', 'postprocess_inputs', 'shuffle_buffer_size', 'output', 'output_config', 'output_compress_columns', 'output_max_file_size', 'offline_sampling', 'evaluation_interval', 'evaluation_duration', 'evaluation_duration_unit', 'evaluation_sample_timeout_s', 'evaluation_parallel_to_training', 'evaluation_force_reset_envs_before_iteration', 'evaluation_config', 'off_policy_estimation_methods', 'ope_split_batch_by_episode', 'evaluation_num_env_runners', 'always_attach_evaluation_results', 'in_evaluation', 'sync_filters_on_rollout_workers_timeout_s', 'keep_per_episode_custom_metrics', 'metrics_episode_collection_timeout_s', 'metrics_num_episodes_for_smoothing', 'min_time_s_per_iteration', 'min_train_timesteps_per_iteration', 'min_sample_timesteps_per_iteration', 'export_native_model_files', 'checkpoint_trainable_policies_only', 'logger_creator', 'logger_config', 'log_level', 'log_sys_usage', 'fake_sampler', 'seed', '_run_training_always_in_thread', '_evaluation_parallel_to_training_wo_thread', 'ignore_env_runner_failures', 'recreate_failed_env_runners', 'max_num_env_runner_restarts', 'delay_between_env_runner_restarts_s', 'restart_failed_sub_environments', 'num_consecutive_env_runner_failures_tolerance', 'env_runner_health_probe_timeout_s', 'env_runner_restore_timeout_s', '_model_config_dict', '_rl_module_spec', '_AlgorithmConfig__prior_exploration_config', '_enable_new_api_stack', '_tf_policy_handles_more_than_one_loss', '_disable_preprocessor_api', '_disable_action_flattening', '_disable_initialize_loss_from_dummy_batch', 'evaluation_num_workers', 'simple_optimizer', 'policy_map_cache', 'worker_cls', 'synchronize_filters', 'enable_async_evaluation', 'custom_async_evaluation_function', '_enable_rl_module_api', 'auto_wrap_old_gym_envs', 'disable_env_checking', 'replay_sequence_length', '_disable_execution_plan_api', 'epsilon', 'target_network_update_freq', 'num_steps_sampled_before_learning_starts', 'store_buffer_in_checkpoints', 'lr_schedule', 'adam_epsilon', 'tau', 'num_atoms', 'v_min', 'v_max', 'noisy', 'sigma0', 'dueling', 'hiddens', 'double_q', 'n_step', 'before_learn_on_batch', 'training_intensity', 'td_error_loss_fn', 'categorical_distribution_temperature', 'replay_buffer_config', 'input', 'policies', 'callbacks', 'create_env_on_driver', 'custom_eval_function', 'framework', 'num_cpus_for_driver', 'num_workers'])\n"
     ]
    }
   ],
   "source": [
    "config = DQNConfig()\n",
    "print(config.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a62d395e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 35\u001b[0m\n\u001b[0;32m      1\u001b[0m my_configs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m      2\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBreakoutDeterministic-v4\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     zero_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 35\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m my_configs\u001b[38;5;241m.\u001b[39menv\n\u001b[0;32m     36\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframework\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m my_configs\u001b[38;5;241m.\u001b[39mframework\n\u001b[0;32m     37\u001b[0m condig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdouble_q\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m my_configs\u001b[38;5;241m.\u001b[39mdouble_q\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'env'"
     ]
    }
   ],
   "source": [
    "config['double_q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b630070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
